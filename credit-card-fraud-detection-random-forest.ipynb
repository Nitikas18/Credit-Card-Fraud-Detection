{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":23498,"sourceType":"datasetVersion","datasetId":310}],"dockerImageVersionId":30042,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#import libraries\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns \nfrom matplotlib import gridspec ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load dataset\ndata = pd.read_csv(\"../input/creditcardfraud/creditcard.csv\") ","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head(10) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#describing the data\nprint(data.shape) \nprint(data.describe()) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#imbalance in the data\nfraud = data[data['Class'] == 1] \nvalid = data[data['Class'] == 0] \noutlierFraction = len(fraud)/float(len(valid)) \nprint(outlierFraction) \nprint('Fraud Cases: {}'.format(len(data[data['Class'] == 1]))) \nprint('Valid Transactions: {}'.format(len(data[data['Class'] == 0]))) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#the amount details for fraudulent transaction\nfraud.Amount.describe() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#the amount details for normal transaction\nvalid.Amount.describe() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plotting the correlation matrix\ncorrmat = data.corr() \nfig = plt.figure(figsize = (12, 9)) \nsns.heatmap(corrmat, vmax = .8, square = True) \nplt.show() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#separating the X and the Y values\nX = data.drop(['Class'], axis = 1) \nY = data[\"Class\"] \nprint(X.shape) \nprint(Y.shape) \n# getting just the values for the sake of processing  \n# (its a numpy array with no columns) \nxData = X.values \nyData = Y.values ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#training and testing data bifurcation\nfrom sklearn.model_selection import train_test_split \n#split the data into training and testing sets \nxTrain, xTest, yTrain, yTest = train_test_split(xData, yData, test_size = 0.2, random_state = 42) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#building the Random Forest Classifier\nfrom sklearn.ensemble import RandomForestClassifier \n#random forest model creation \nrfc = RandomForestClassifier() \nrfc.fit(xTrain, yTrain) \n#predictions \nyPred = rfc.predict(xTest) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#building all kinds of evaluating parameters\nfrom sklearn.metrics import classification_report, accuracy_score  \nfrom sklearn.metrics import precision_score, recall_score \nfrom sklearn.metrics import f1_score, matthews_corrcoef \nfrom sklearn.metrics import confusion_matrix \n  \nn_outliers = len(fraud) \nn_errors = (yPred != yTest).sum() \nprint(\"The model used is Random Forest classifier\") \n  \nacc = accuracy_score(yTest, yPred) \nprint(\"The accuracy is {}\".format(acc)) \n  \nprec = precision_score(yTest, yPred) \nprint(\"The precision is {}\".format(prec)) \n  \nrec = recall_score(yTest, yPred) \nprint(\"The recall is {}\".format(rec)) \n  \nf1 = f1_score(yTest, yPred) \nprint(\"The F1-Score is {}\".format(f1)) \n  \nMCC = matthews_corrcoef(yTest, yPred) \nprint(\"The Matthews correlation coefficient is{}\".format(MCC)) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#visulalizing the confusion matrix\nLABELS = ['Normal', 'Fraud'] \nconf_matrix = confusion_matrix(yTest, yPred) \nplt.figure(figsize =(12, 12)) \nsns.heatmap(conf_matrix, xticklabels = LABELS, yticklabels = LABELS, annot = True, fmt =\"d\"); \nplt.title(\"Confusion matrix\") \nplt.ylabel('True class') \nplt.xlabel('Predicted class') \nplt.show() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}